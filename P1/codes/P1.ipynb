{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Mao Nishino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Loaded 7291 data for train data\n",
      "Loaded 2007 data for train data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def load_data(path: str):\n",
    "    \"\"\" Load the data and make a list of (index, data tensor).\n",
    "    Args:   \n",
    "        path: the path of the file to read  the data from.\n",
    "    Returns:\n",
    "        data_list: a list of tuples, each tuple contains the index of the data and the data tensor.\n",
    "    \"\"\"\n",
    "    with open(path) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    float_lines = [[float(string) for string in line.split()] for line in lines]\n",
    "    data_list = [(torch.tensor(line[1:]).reshape(1,16,16), int(line[0])) for line in float_lines]\n",
    "    return data_list\n",
    "\n",
    "train_list = load_data('../zip_train.txt')\n",
    "test_list = load_data('../zip_test.txt')\n",
    "\n",
    "print(f\"Loaded {len(train_list)} data for train data\")\n",
    "print(f\"Loaded {len(test_list)} data for train data\")\n",
    "\n",
    "# Define PyTorch Dataset\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "# Create PyTorch Dataset\n",
    "train_dataset = MyDataset(train_list)\n",
    "test_dataset = MyDataset(test_list)\n",
    "\n",
    "# Split the train dataset into train and validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define a 4 layer ReLU neural network\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, n1, n2, n3, activations):\n",
    "        \"\"\" Define the layers of the neural network.\n",
    "        \n",
    "        Args:\n",
    "            n1: the number of neurons in the first layer.\n",
    "            n2: the number of neurons in the second layer.\n",
    "            n3: the number of neurons in the third layer.\n",
    "            activations: a list of strings, each string is the name of the activation function to use in the corresponding layer.\n",
    "            \"\"\"\n",
    "        \n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.activation_functions = {\n",
    "            \"relu\": torch.nn.ReLU(),\n",
    "            \"sigmoid\": torch.nn.Sigmoid()\n",
    "        }\n",
    "        self.layer1 = torch.nn.Linear(256, n1)\n",
    "        self.layer2 = torch.nn.Linear(n1, n2)\n",
    "        self.layer3 = torch.nn.Linear(n2, n3)\n",
    "        self.layer4 = torch.nn.Linear(n3, 10)\n",
    "\n",
    "        self.activations = torch.nn.ModuleList([self.activation_functions[activation] for activation in activations])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.activations[0](x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activations[1](x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.activations[2](x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.activations[3](x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model - This corresponds to 1 epoch\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Test the model\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    return correct\n",
    "\n",
    "def random_search_4layerReLU():\n",
    "    \"\"\" Random search for 4 layer ReLU neural network hyperparameters.\n",
    "\n",
    "    We will employ the \"coarse to fine\" strategy on the number of neurons in each layer.\n",
    "    At the beginning, each layer will have a range of 10 to 2024 neurons. \n",
    "    Then, we will reduce the range to 10 to the best number of neurons found in the previous iteration so that we can find the best number of neurons in a smaller range.\n",
    "    Moreover, we will double the number of samples, +10 the epochs, and half the batch size in each iteration to get a more accurate result.\n",
    "    \n",
    "    \"\"\"\n",
    "    best_accuracy = 0\n",
    "    best_n = [1024, 1024, 1024]\n",
    "    new_best_n = best_n\n",
    "    samples = 200\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "\n",
    "    for _ in range(3):\n",
    "        # Create dataloaders\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        for _ in range(samples):\n",
    "            n3 = torch.randint(10, max(best_n[2],11), (1,)).item()\n",
    "            n2 = torch.randint(n3, max(best_n[1],11), (1,)).item()\n",
    "            n1 = torch.randint(n2, max(best_n[0],11), (1,)).item()\n",
    "\n",
    "            activation_options = ['relu'] \n",
    "            activations = [random.choice(activation_options) for _ in range(4)]\n",
    "\n",
    "            model = NeuralNetwork(n1, n2, n3, activations).to(device)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) # Fixed learning rate for simplicity\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                train(train_dataloader, model, loss_fn, optimizer)\n",
    "            \n",
    "            accuracy = test(val_dataloader, model, loss_fn)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                new_best_n = [n1, n2, n3]\n",
    "                print(f\"Best (n1, n2, n3): {new_best_n}, Best Activations: {activations}, Accuracy: {(100*best_accuracy):>0.1f}%\")\n",
    "                print(f\"Epochs: {epochs}, Batch size: {batch_size}\")\n",
    "        best_n = new_best_n\n",
    "\n",
    "        samples //= 2\n",
    "        epochs += 10\n",
    "        batch_size //= 2\n",
    "        print(f\"Now the best n is {best_n} and the number of samples is {samples} and the number of epochs is {epochs} and the batch size is {batch_size}\")\n",
    "\n",
    "# random_search_4layerReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally Connected NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocallyConnected2D(torch.nn.Module):\n",
    "    \"\"\" Defines a locally connected layer. Basically it is a convolutional layer without weight sharing.\n",
    "\n",
    "    Args:\n",
    "        in_channels: the number of input channels.\n",
    "        out_channels: the number of output channels.\n",
    "        output_size: (H, W) of the output tensor.\n",
    "        kernel_size: the size of the kernel.\n",
    "        stride: the stride of the kernel.\n",
    "\n",
    "        For an input tensor of shape (N, C, H, W), the output tensor will have the shape \\\n",
    "              (N, out_channels, output_size[0], output_size[1]).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, output_size, kernel_size, stride=1):\n",
    "        super(LocallyConnected2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = torch.nn.modules.utils._pair(kernel_size)\n",
    "        self.stride = torch.nn.modules.utils._pair(stride)\n",
    "        self.output_size = output_size\n",
    "        self.weight = torch.nn.Parameter(\n",
    "            torch.randn(1, out_channels, in_channels*kernel_size**2, output_size[0]*output_size[1])\n",
    "        )\n",
    "        self.bias = torch.nn.Parameter(torch.randn(1, out_channels, output_size[0]*output_size[1]))\n",
    "      \n",
    "    def forward(self, x):\n",
    "      kH, kW = self.kernel_size\n",
    "      sH, sW = self.stride\n",
    "      n, _, _, _ = x.shape\n",
    "      x = torch.nn.functional.unfold(x, (kH, kW), (sH, sW))\n",
    "      x = x.unsqueeze(dim=1)*self.weight\n",
    "      x = x.sum(dim=2)\n",
    "      x = x + self.bias\n",
    "      x = torch.nn.functional.fold(x, self.output_size, (sH, sW))\n",
    "      return x.reshape(n, self.out_channels, self.output_size[0], self.output_size[1])\n",
    "    \n",
    "def output_size_calc(H_in, W_in, kernel_size, stride = 1):\n",
    "    \"\"\" Calculate the output size of a locally connected layer.\n",
    "\n",
    "    Args:\n",
    "            H_in: the height of the input tensor.\n",
    "            W_in: the width of the input tensor.\n",
    "            kernel_size: the size of the kernel.\n",
    "            stride: the stride of the kernel.\n",
    "\n",
    "    Returns:\n",
    "        H_out: the height of the output tensor.\n",
    "        W_out: the width of the output tensor.\n",
    "\n",
    "    We use the formula\n",
    "    H_out = (H_in - kernel_size) // stride + 1\n",
    "    W_out = (W_in - kernel_size) // stride + 1\n",
    "    \"\"\"\n",
    "    H_out = (H_in - kernel_size) // stride + 1\n",
    "    W_out = (W_in - kernel_size) // stride + 1\n",
    "    return H_out, W_out\n",
    "\n",
    "# Mimic the convolutional neural network by locally connected layers\n",
    "\n",
    "class LocallyConnectedNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LocallyConnectedNeuralNetwork, self).__init__()\n",
    "        self.conv1 = LocallyConnected2D(in_channels=1, out_channels=4, kernel_size=5, output_size=output_size_calc(16, 16, 5))\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        insize_conv2 = output_size_calc(*output_size_calc(16, 16, 5), 2)\n",
    "        self.conv2 = LocallyConnected2D(in_channels=4, out_channels=12, kernel_size=3, output_size=output_size_calc(*insize_conv2, 3))\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(12*4*4, 84)\n",
    "        self.fc2 = torch.nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 12*4*4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Accuracy: 14.3%\n",
      "Epoch [2/30], Accuracy: 14.3%\n",
      "Epoch [3/30], Accuracy: 14.3%\n",
      "Epoch [4/30], Accuracy: 14.2%\n",
      "Epoch [5/30], Accuracy: 14.2%\n",
      "Epoch [6/30], Accuracy: 15.3%\n",
      "Epoch [7/30], Accuracy: 22.1%\n",
      "Epoch [8/30], Accuracy: 61.8%\n",
      "Epoch [9/30], Accuracy: 53.1%\n",
      "Epoch [10/30], Accuracy: 69.1%\n",
      "Epoch [11/30], Accuracy: 67.6%\n",
      "Epoch [12/30], Accuracy: 70.4%\n",
      "Epoch [13/30], Accuracy: 78.2%\n",
      "Epoch [14/30], Accuracy: 84.6%\n",
      "Epoch [15/30], Accuracy: 85.7%\n",
      "Epoch [16/30], Accuracy: 86.2%\n",
      "Epoch [17/30], Accuracy: 85.1%\n",
      "Epoch [18/30], Accuracy: 83.5%\n",
      "Epoch [19/30], Accuracy: 87.0%\n",
      "Epoch [20/30], Accuracy: 88.3%\n",
      "Epoch [21/30], Accuracy: 88.9%\n",
      "Epoch [22/30], Accuracy: 87.9%\n",
      "Epoch [23/30], Accuracy: 89.2%\n",
      "Epoch [24/30], Accuracy: 84.6%\n",
      "Epoch [25/30], Accuracy: 83.1%\n",
      "Epoch [26/30], Accuracy: 89.8%\n",
      "Epoch [27/30], Accuracy: 89.7%\n",
      "Epoch [28/30], Accuracy: 90.4%\n",
      "Epoch [29/30], Accuracy: 89.9%\n",
      "Epoch [30/30], Accuracy: 90.3%\n"
     ]
    }
   ],
   "source": [
    "# Train the locally connected neural network\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 8\n",
    "\n",
    "model = LocallyConnectedNeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) # Fixed learning rate for simplicity\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    accuracy = test(val_dataloader, model, loss_fn)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Accuracy: {(100*accuracy):>0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=4, out_channels=12, kernel_size=3)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(12*4*4, 84)\n",
    "        self.fc2 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 12*4*4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Accuracy: 65.0%\n",
      "Epoch [2/30], Accuracy: 79.0%\n",
      "Epoch [3/30], Accuracy: 83.1%\n",
      "Epoch [4/30], Accuracy: 84.9%\n",
      "Epoch [5/30], Accuracy: 85.8%\n",
      "Epoch [6/30], Accuracy: 87.5%\n",
      "Epoch [7/30], Accuracy: 88.8%\n",
      "Epoch [8/30], Accuracy: 89.0%\n",
      "Epoch [9/30], Accuracy: 89.4%\n",
      "Epoch [10/30], Accuracy: 89.2%\n",
      "Epoch [11/30], Accuracy: 89.0%\n",
      "Epoch [12/30], Accuracy: 88.8%\n",
      "Epoch [13/30], Accuracy: 89.2%\n",
      "Epoch [14/30], Accuracy: 89.2%\n",
      "Epoch [15/30], Accuracy: 89.8%\n",
      "Epoch [16/30], Accuracy: 89.8%\n",
      "Epoch [17/30], Accuracy: 89.7%\n",
      "Epoch [18/30], Accuracy: 97.0%\n",
      "Epoch [19/30], Accuracy: 97.1%\n",
      "Epoch [20/30], Accuracy: 97.7%\n",
      "Epoch [21/30], Accuracy: 97.2%\n",
      "Epoch [22/30], Accuracy: 97.3%\n",
      "Epoch [23/30], Accuracy: 97.6%\n",
      "Epoch [24/30], Accuracy: 97.9%\n",
      "Epoch [25/30], Accuracy: 97.6%\n",
      "Epoch [26/30], Accuracy: 97.5%\n",
      "Epoch [27/30], Accuracy: 97.8%\n",
      "Epoch [28/30], Accuracy: 97.5%\n",
      "Epoch [29/30], Accuracy: 97.9%\n",
      "Epoch [30/30], Accuracy: 97.7%\n"
     ]
    }
   ],
   "source": [
    "# Train the convolutional neural network\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 8\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) # Fixed learning rate for simplicity\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    accuracy = test(val_dataloader, model, loss_fn)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Accuracy: {(100*accuracy):>0.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAP5619-SP24_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
